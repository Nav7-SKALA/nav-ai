
import os
# from sentence_transformers import SentenceTransformer
# from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser

import sys
sys.path.append('..') 
from vector_store.chroma_client import get_chroma_client

from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

from langchain_huggingface import HuggingFaceEmbeddings

_embedding_model = None

def get_embedding_model():
    global _embedding_model
    
    if _embedding_model is None:
        print("ğŸ”„ LangChain HuggingFace ì„ë² ë”© ë¡œë“œ ì¤‘...")
        _embedding_model = HuggingFaceEmbeddings(
            model_name=os.getenv("EMBEDDING_MODEL_NAME"),
            model_kwargs={'device': 'cpu'}
        )
        print("âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    
    return _embedding_model



def find_best_match(query_text: str, user_id: str):
    """ì¿¼ë¦¬ì— ê°€ì¥ ì í•©í•œ ì¸ì¬ ì°¾ê¸°"""
    
    # 1. ìƒìœ„ 10ëª… ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    candidates = get_topN_info(query_text, user_id, 10)  # user_id ë„˜ê²¨ì£¼ê¸°
    
    # 2. LLMìœ¼ë¡œ 5ëª… ì„ íƒ
    emp_ids = llm_select(query_text, candidates)
    
    # 3. ì„ íƒëœ ì‚¬ë²ˆìœ¼ë¡œ ìƒì„¸ ì •ë³´ ë°˜í™˜
    # emp_id = re.search(r'EMP-\d+', llm_choice).group(0)
    return get_multiple_employees_detail(emp_ids)


def get_user_entry_year(profile_id: str):
    """ì‚¬ìš©ìì˜ ì…ì‚¬ë…„ë„ ì¡°íšŒ"""
    client = get_chroma_client()
    collection_name = os.getenv("JSON_HISTORY_COLLECTION_NAME")
    collection = client.get_collection(name=collection_name)

    results = collection.get(where={"profileId": profile_id}, include=["metadatas"])
    years = [meta.get("ì…ì‚¬ë…„ë„") for meta in results.get("metadatas", []) if "ì…ì‚¬ë…„ë„" in meta]
    
    return years[0]

def get_topN_info(query_text, user_id, top_n, grade=None, years=False):
    """(LLM ìœ„í•œ) ìƒìœ„ nëª… ê°„ë‹¨ ì •ë³´"""
    client = get_chroma_client()
    collection_name = os.getenv("JSON_HISTORY_COLLECTION_NAME")
    collection = client.get_collection(name=collection_name)
    print('------------ì„ë² ë”© ìƒì„± ì‹œì‘---------------')
    # ì„ë² ë”© ìƒì„±
    embedding_model = get_embedding_model() #SentenceTransformer(os.getenv("EMBEDDING_MODEL_NAME"), device='cpu')
    query_embedding = [embedding_model.embed_query(query_text)] #embedding_model.encode([query_text]).tolist()
    print('------------ì„ë² ë”© ìƒì„± ì™„ë£Œ---------------')
    # í•„í„° êµ¬ì„±
    where_filter = None
    if grade is not None or years:
        where_filter = {}
        
        # Grade í•„í„°ë§ (ë‹¨ì¼ ê°’)
        if grade is not None:
            where_filter["grade"] = {"$eq": grade}
        
        # ì—°ì°¨ í•„í„°ë§
        if years:
            entry_year = get_user_entry_year(user_id)
            cutoff_year = entry_year - 1
            where_filter = {
                "$and": [
                    {"ì…ì‚¬ë…„ë„": {"$gte": cutoff_year}},
                    {"grade": {"$ne": 'CL4'}}
                ]
            }

    # ë””ë²„ê¹…ìš© ì¶œë ¥
    print(f"ğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: {query_text}")
    print(f"ğŸ” í•„í„° ì¡°ê±´: {where_filter}")

    # ê²€ìƒ‰ ì‹¤í–‰
    results = collection.query(
        query_embeddings=query_embedding,
        n_results=20,
        include=['metadatas'],
        where=where_filter
    )

    # ê²°ê³¼ í™•ì¸
    print(f"ğŸ” ê²€ìƒ‰ ê²°ê³¼ ìˆ˜: {len(results['metadatas'][0]) if results['metadatas'] else 0}")

    # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš° ì²˜ë¦¬
    if not results['metadatas'] or not results['metadatas'][0]:
        print("âŒ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. í•„í„° ì¡°ê±´ì„ í™•ì¸í•˜ì„¸ìš”.")
        return ""

    # ì¤‘ë³µ ì œê±° ë° ìƒìœ„ top_n ì¶”ì¶œ (ì‚¬ë²ˆê³¼ profileId ë‘˜ ë‹¤ ì €ì¥)
    seen = set()
    topN = []
    for meta in results['metadatas'][0]:
        # ì‚¬ë²ˆì´ ì—†ëŠ” í–‰ì€ ìŠ¤í‚µ
        if 'ì‚¬ë²ˆ' not in meta or not meta['ì‚¬ë²ˆ']:
            continue

        emp_id = meta.get('ì‚¬ë²ˆ', '')
        profile_id = meta.get('profileId', emp_id)  # profileIdê°€ ì—†ìœ¼ë©´ ì‚¬ë²ˆ ì‚¬ìš©
        
        if emp_id not in seen and emp_id != user_id:
            seen.add(emp_id)
            topN.append(profile_id)  # profileIdë¥¼ ì €ì¥
            # print(f"ğŸ” ëŒ€ìƒì ì¶”ê°€: ì‚¬ë²ˆ={emp_id}, profileId={profile_id}")
            if len(topN) == top_n:
                break

    print(f"ğŸ” ì¤‘ë³µ ì œê±° í›„ ëŒ€ìƒì: {len(topN)}ëª…")
    # print(f"ğŸ” ëŒ€ìƒì profileId ëª©ë¡: {topN}")

    # profileIdë³„ ìƒì„¸ ê²½ë ¥ ì •ë³´ ì¶”ì¶œ
    info = ""
    for i, profile_id in enumerate(topN, 1):
        # print(f"ğŸ” {i}ë²ˆì§¸ ëŒ€ìƒì profileId: {profile_id} ì¡°íšŒ ì¤‘...")
        
        emp_data = collection.get(where={"profileId": profile_id}, include=['metadatas'])
        # print(f"ğŸ” {profile_id} ì¡°íšŒ ê²°ê³¼: {len(emp_data['metadatas']) if emp_data['metadatas'] else 0}ê±´")
        
        if not emp_data['metadatas']:
            # print(f"âŒ profileId {profile_id}ì— ëŒ€í•œ ìƒì„¸ ì •ë³´ ì—†ìŒ")
            continue

        first_meta = emp_data['metadatas'][0]
        info += f"\n{i}. profileId: {profile_id}\n"
        info += f"   ì‚¬ë²ˆ: {first_meta['ì‚¬ë²ˆ']}\n"
        info += f"   Grade: {first_meta['grade']}\n"
        info += f"   ì…ì‚¬ë…„ë„: {first_meta['ì…ì‚¬ë…„ë„']}\n"
        info += f"   ê²½ë ¥íë¦„:\n"

        careers = sorted(emp_data['metadatas'], key=lambda x: x['ì—°ì°¨'])
        for j, career in enumerate(careers, 1):
            info += f"     {j}. {career['ì—°ì°¨']} - {career['ì—­í• ']}\n"
            info += f"        ìŠ¤í‚¬ì…‹: {career['ìŠ¤í‚¬ì…‹']}\n"
            info += f"        ë„ë©”ì¸: {career['ë„ë©”ì¸']}\n"
            info += f"        í”„ë¡œì íŠ¸ê·œëª¨: {career['í”„ë¡œì íŠ¸ê·œëª¨']}\n"
            info += f"        ìš”ì•½: {career['ìš”ì•½']}\n"

        info += "-" * 50 + "\n"
        # print(f"ğŸ” {i}ë²ˆì§¸ ëŒ€ìƒì ì •ë³´ ì¶”ê°€ ì™„ë£Œ")
    
    # print(f"ğŸ“Š ìµœì¢… ì •ë³´ ê¸¸ì´: {len(info)} ë¬¸ì")
    return info


def get_topN_emp(query_text, user_id, top_n):
    """(roleModel agent ìœ„í•œ) ìƒìœ„ nëª… ì¶”ì¶œ - ê°œì„ ëœ ë²„ì „"""
    try:
        client = get_chroma_client()
        collection = client.get_collection(name=os.getenv("JSON_HISTORY_COLLECTION_NAME"))
        embedding_model = get_embedding_model() #SentenceTransformer(os.getenv("EMBEDDING_MODEL_NAME"), device='cpu')
        query_embedding = [embedding_model.embed_query(query_text)] #embedding_model.encode([query_text]).tolist()
        
        results = collection.query(query_embeddings=query_embedding, n_results=20, include=['metadatas'])
        
        # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš° ì²˜ë¦¬
        if not results['metadatas'] or not results['metadatas'][0]:
            print("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return ""
        
        # ì¤‘ë³µ ì œê±°ë¡œ nëª… ì„ íƒ
        seen = set()
        topN = []
        for meta in results['metadatas'][0]:
            emp_id = meta.get('ì‚¬ë²ˆ')  # .get() ì‚¬ìš©ìœ¼ë¡œ KeyError ë°©ì§€
            if emp_id and emp_id not in seen and emp_id != user_id:
                seen.add(emp_id)
                topN.append(emp_id)
                if len(topN) == top_n:
                    break
        
        # ì„ íƒëœ ì§ì›ì´ ì—†ëŠ” ê²½ìš° ì²˜ë¦¬
        if not topN:
            print(f"ì„ íƒëœ ì§ì›ì´ ì—†ìŠµë‹ˆë‹¤. (user_id: {user_id} ì œì™¸ í›„)")
            return ""
        
        # print(f"ì„ íƒëœ ì§ì› {len(topN)}ëª…: {topN}")
        
        # ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        info = get_multiple_employees_detail(topN)
        
        # ë¹ˆ ê²°ê³¼ì¸ ê²½ìš° ì²˜ë¦¬
        if not info or info.strip() == "" or info.strip() == "\n" + "="*50:
            print("ìƒì„¸ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨")
            return ""
            
        return info
        
    except Exception as e:
        print(f"get_topN_emp ì˜¤ë¥˜: {e}")
        return ""


def llm_select(query_text, candidates):
    """LLMìœ¼ë¡œ 5ëª… ì„ íƒ"""
    llm = ChatOpenAI(model=os.getenv("MODEL_NAME"), temperature=0.3)
    
    prompt = PromptTemplate(
        input_variables=["query", "candidates"],
        template="""
    ì¿¼ë¦¬ì— ê°€ì¥ ì í•©í•œ ì¸ì¬ 5ëª…ì„ ì„ íƒí•´ì£¼ì„¸ìš”.

    **ì‚¬ìš©ì ìš”ì²­:**
    {query}

    **í›„ë³´ìë“¤:**
    {candidates}

    **í‰ê°€ ê¸°ì¤€:**
    1. ì¿¼ë¦¬ì™€ì˜ ê´€ë ¨ì„± (ê¸°ìˆ  ìŠ¤íƒ, ê²½í—˜, ì—­í•  ë“±)
    2. ê²½ë ¥ ìˆ˜ì¤€ê³¼ ì í•©ì„±
    3. ë„ë©”ì¸ ê²½í—˜
    4. ì„±ì¥ ê°€ëŠ¥ì„± ë° ì „í™˜ ê°€ëŠ¥ì„±

    **ì¶œë ¥ í˜•ì‹:**
    ë°˜ë“œì‹œ ì„ íƒëœ ì¸ì¬(ID)ë§Œ ì½¤ë§ˆë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì—°ê²°í•˜ì—¬ ì¶œë ¥í•˜ì„¸ìš”.

    ì˜ˆì‹œ: EMP001, EMP002, EMP003, EMP004, EMP005

    ì„ íƒ: [profileId]
    ì´ìœ : [ê°„ë‹¨í•œ ì„ íƒ ì´ìœ ]
"""
    )
    
    chain = prompt | llm | StrOutputParser()
    result = chain.invoke({"query": query_text, "candidates": candidates})
    
    ids = [id.strip() for id in result.strip().split(',')]
    return ids


def get_multiple_employees_detail(emp_ids):
    """ì„ íƒëœ ì—¬ëŸ¬ ì‚¬ì›ë“¤ì˜ ìƒì„¸ ì •ë³´ë¥¼ í•©ì³ì„œ ë°˜í™˜"""
    client = get_chroma_client()
    collection = client.get_collection(name=os.getenv("JSON_HISTORY_COLLECTION_NAME"))
    
    all_results = []
    
    for emp_id in emp_ids:
        try:
            emp_data = collection.get(where={"ì‚¬ë²ˆ": emp_id}, include=['metadatas', 'documents'])
            
            if not emp_data['metadatas']:  # ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° ìŠ¤í‚µ
                continue
                
            result = f"=== ì„ íƒëœ ì‚¬ì› ({emp_id}) ===\n"
            first_meta = emp_data['metadatas'][0]
            result += f"ì‚¬ë²ˆ: {first_meta['ì‚¬ë²ˆ']}\n"
            result += f"Grade: {first_meta['grade']}\n"
            result += f"ì…ì‚¬ë…„ë„: {first_meta['ì…ì‚¬ë…„ë„']}\n"
            result += f"ì´ ê²½ë ¥ ìˆ˜: {len(emp_data['metadatas'])}ê°œ\n\n"
            
            result += "ê²½ë ¥ ìƒì„¸:\n"
            for j, (meta, doc) in enumerate(zip(emp_data['metadatas'], emp_data['documents']), 1):
                result += f"  ê²½ë ¥ {j}: {meta['ì—°ì°¨']} - {meta['ì—­í• ']}\n"
                result += f"    ìŠ¤í‚¬ì…‹: {meta['ìŠ¤í‚¬ì…‹']}\n"
                result += f"    ë„ë©”ì¸: {meta['ë„ë©”ì¸']}\n"
                result += f"    í”„ë¡œì íŠ¸ê·œëª¨: {meta['í”„ë¡œì íŠ¸ê·œëª¨']}\n"
                result += f"    ìš”ì•½: {meta['ìš”ì•½']}\n"
                result += f"    ìƒì„¸ë‚´ìš©: {doc}\n\n"
            
            all_results.append(result)
            
        except Exception as e:
            print(f"ì§ì› {emp_id} ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            continue
    
    # ëª¨ë“  ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ í•©ì¹˜ê¸°
    combined_result = "\n" + ("="*50 + "\n").join(all_results)
    return combined_result


def get_employee_detail(profile_id):
    """ì„ íƒëœ ì‚¬ì› ìƒì„¸ ì •ë³´"""
    client = get_chroma_client()
    collection = client.get_collection(name=os.getenv("JSON_HISTORY_COLLECTION_NAME"))
    
    emp_data = collection.get(where={"profileId": profile_id}, include=['metadatas', 'documents'])

    if not emp_data['metadatas']:
        return f"profileId '{profile_id}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    result = f"=== ì„ íƒëœ ì‚¬ì› ===\n"
    first_meta = emp_data['metadatas'][0]
    result += f"profileId: {first_meta['profileId']}\n"
    result += f"ì‚¬ë²ˆ: {first_meta['ì‚¬ë²ˆ']}\n"
    result += f"Grade: {first_meta['grade']}\n"
    result += f"ì…ì‚¬ë…„ë„: {first_meta['ì…ì‚¬ë…„ë„']}\n"
    result += f"ì´ ê²½ë ¥ ìˆ˜: {len(emp_data['metadatas'])}ê°œ\n\n"
    
    result += "ê²½ë ¥ ìƒì„¸:\n"
    for j, (meta, doc) in enumerate(zip(emp_data['metadatas'], emp_data['documents']), 1):
        result += f"  ê²½ë ¥ {j}: {meta['ì—°ì°¨']} - {meta['ì—­í• ']}\n"
        result += f"    ìŠ¤í‚¬ì…‹: {meta['ìŠ¤í‚¬ì…‹']}\n"
        result += f"    ë„ë©”ì¸: {meta['ë„ë©”ì¸']}\n"
        result += f"    í”„ë¡œì íŠ¸ê·œëª¨: {meta['í”„ë¡œì íŠ¸ê·œëª¨']}\n"
        result += f"    ìš”ì•½: {meta['ìš”ì•½']}\n"
        result += f"    ìƒì„¸ë‚´ìš©: {doc}\n\n"
    
    return result


if __name__ == "__main__":
    result = find_best_match("ê¸ˆìœµí”„ë¡œì íŠ¸ pm", user_id=1)
    print(result)
