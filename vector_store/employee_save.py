# import os
# import glob
# from dotenv import load_dotenv
# from tqdm import tqdm
# import sys

# from langchain_chroma import Chroma
# from langchain_community.embeddings import HuggingFaceEmbeddings
# from langchain.schema import Document

# load_dotenv()


# EMBEDDING_MODEL_NAME = os.getenv("EMBEDDING_MODEL_NAME")
# VECTOR_DB_DIR = os.getenv("VECTOR_DB_DIR")
# EMP_DATA_DIR = os.getenv("EMP_DATA_DIR")
# HISTORY_COLLECTION_NAME = os.getenv("HISTORY_COLLECTION_NAME")



# # í™˜ê²½ ë³€ìˆ˜ í™•ì¸
# if not EMBEDDING_MODEL_NAME:
#     print("ì˜¤ë¥˜: EMBEDDING_MODEL_NAME í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
#     sys.exit(1)
# if not VECTOR_DB_DIR:
#     print("ì˜¤ë¥˜: VECTOR_DB_DIR í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
#     sys.exit(1)
# if not EMP_DATA_DIR:
#     print("ì˜¤ë¥˜: EMP_DATA_DIR í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
#     sys.exit(1)
# if not HISTORY_COLLECTION_NAME:
#     print("ì˜¤ë¥˜: HISTORY_COLLECTION_NAME í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
#     sys.exit(1)

# def save_emp_docs():
#     # 1) ì„ë² ë”© ëª¨ë¸ ì¤€ë¹„
#     embeddings = HuggingFaceEmbeddings(
#         model_name=EMBEDDING_MODEL_NAME,
#         model_kwargs={'device': 'cpu'},
#         encode_kwargs={'normalize_embeddings': True, 'clean_up_tokenization_spaces': False}
#     )

#     # 2) ChromaDB ì»¬ë ‰ì…˜ ì¤€ë¹„ (ìˆ˜ì •ëœ ë¶€ë¶„)
#     vectordb = Chroma(
#         persist_directory=VECTOR_DB_DIR,
#         embedding_function=embeddings,
#         collection_name=HISTORY_COLLECTION_NAME
#     )
#     print(f"ğŸ”— ì»¬ë ‰ì…˜ ì—°ê²°: {HISTORY_COLLECTION_NAME}")

#     # 3) íŒŒì¼ í™•ì¸
#     files = sorted(glob.glob(os.path.join(EMP_DATA_DIR, "*.txt")))
#     print(f"ğŸ“ ì²˜ë¦¬í•  íŒŒì¼: {len(files)}ê°œ")
    
#     if not files:
#         raise FileNotFoundError(f"No .txt files in {EMP_DATA_DIR}")

#     documents_to_add = []
    
#     # 4) íŒŒì¼ ì²˜ë¦¬
#     for idx, path in enumerate(files, start=1):
#         emp_id = os.path.splitext(os.path.basename(path))[0]
        
#         with open(path, "r", encoding="utf-8") as f:
#             text = f.read().strip()
        
#         if not text:
#             print(f"âš ï¸ ë¹ˆ íŒŒì¼ ê±´ë„ˆë›°ê¸°: {emp_id}")
#             continue

#         # LangChain Document ê°ì²´ ìƒì„±
#         doc = Document(
#             page_content=text,
#             metadata={
#                 "profileId": idx,
#                 "employeeId": emp_id,
#                 "career_title": ""
#             }
#         )
#         documents_to_add.append(doc)

#     print(f"ğŸ“ ì¶”ê°€/ì—…ë°ì´íŠ¸í•  ë°ì´í„°: {len(documents_to_add)}ê°œ")

#     # 5) ë°ì´í„° ì¶”ê°€ (LangChain Chromaì˜ add_documents ì‚¬ìš©)
#     # ê¸°ì¡´ IDê°€ ìˆìœ¼ë©´ ìë™ìœ¼ë¡œ ë®ì–´ì“°ê¸°ë©ë‹ˆë‹¤.
#     if documents_to_add:
#         vectordb.add_documents(documents_to_add)
#         print(f"âœ… {len(documents_to_add)}ê°œ ë¬¸ì„œ ì²˜ë¦¬ ì™„ë£Œ (ì¶”ê°€/ì—…ë°ì´íŠ¸)")
#     else:
#         print("ì¶”ê°€í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
    

# if __name__ == "__main__":
#     print('===================================')
#     print(f"í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬: {os.getcwd()}")
#     print(f"VECTOR_DB_DIR: {VECTOR_DB_DIR}")
#     print(f"ì ˆëŒ€ ê²½ë¡œ: {os.path.abspath(VECTOR_DB_DIR)}")
#     print(f"EMP_DATA_DIR: {EMP_DATA_DIR}")
#     print(f"ë°ì´í„° ì ˆëŒ€ ê²½ë¡œ: {os.path.abspath(EMP_DATA_DIR)}")
#     print('===================================')
#     print(f"VECTOR_DB_DIR ì›ë³¸: '{os.getenv('VECTOR_DB_DIR')}'")
#     print(f".env íŒŒì¼ ê²½ë¡œ: {os.path.abspath('.env')}")
#     save_emp_docs()
#     print("=== ChromaDB ì €ì¥ ì™„ë£Œ ===")



import os
import glob
from dotenv import load_dotenv
from tqdm import tqdm
import sys

from langchain_chroma import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.schema import Document
from chroma_client import get_chroma_client  # ì›ê²© í´ë¼ì´ì–¸íŠ¸ ê°€ì ¸ì˜¤ê¸°

load_dotenv()

EMBEDDING_MODEL_NAME = os.getenv("EMBEDDING_MODEL_NAME")
EMP_DATA_DIR = os.getenv("EMP_DATA_DIR")
HISTORY_COLLECTION_NAME = os.getenv("HISTORY_COLLECTION_NAME")

# í™˜ê²½ ë³€ìˆ˜ í™•ì¸ (VECTOR_DB_DIR ì œê±°)
if not EMBEDDING_MODEL_NAME:
    print("ì˜¤ë¥˜: EMBEDDING_MODEL_NAME í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    sys.exit(1)
if not EMP_DATA_DIR:
    print("ì˜¤ë¥˜: EMP_DATA_DIR í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    sys.exit(1)
if not HISTORY_COLLECTION_NAME:
    print("ì˜¤ë¥˜: HISTORY_COLLECTION_NAME í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    sys.exit(1)

def save_emp_docs():
    # 1) ì„ë² ë”© ëª¨ë¸ ì¤€ë¹„
    embeddings = HuggingFaceEmbeddings(
        model_name=EMBEDDING_MODEL_NAME,
        model_kwargs={'device': 'cpu'},
        encode_kwargs={'normalize_embeddings': True, 'clean_up_tokenization_spaces': False}
    )

    # 2) ì›ê²© ChromaDB í´ë¼ì´ì–¸íŠ¸ ìƒì„±
    chroma_client = get_chroma_client()
    
    # 3) LangChain Chromaë¡œ ì›ê²© ì—°ê²°
    vectordb = Chroma(
        client=chroma_client,  # ì›ê²© í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš©
        collection_name=HISTORY_COLLECTION_NAME,
        embedding_function=embeddings,
    )
    print(f"ğŸ”— ì›ê²© ì»¬ë ‰ì…˜ ì—°ê²°: {HISTORY_COLLECTION_NAME}")

    # 4) íŒŒì¼ í™•ì¸
    files = sorted(glob.glob(os.path.join(EMP_DATA_DIR, "*.txt")))
    print(f"ğŸ“ ì²˜ë¦¬í•  íŒŒì¼: {len(files)}ê°œ")
    
    if not files:
        raise FileNotFoundError(f"No .txt files in {EMP_DATA_DIR}")

    documents_to_add = []
    
    # 5) íŒŒì¼ ì²˜ë¦¬
    for idx, path in enumerate(files, start=1):
        emp_id = os.path.splitext(os.path.basename(path))[0]
        
        with open(path, "r", encoding="utf-8") as f:
            text = f.read().strip()
        
        if not text:
            print(f"âš ï¸ ë¹ˆ íŒŒì¼ ê±´ë„ˆë›°ê¸°: {emp_id}")
            continue

        # LangChain Document ê°ì²´ ìƒì„±
        doc = Document(
            page_content=text,
            metadata={
                "profileId": idx,
                "employeeId": emp_id,
                "career_title": ""
            }
        )
        documents_to_add.append(doc)

    print(f"ğŸ“ ì¶”ê°€/ì—…ë°ì´íŠ¸í•  ë°ì´í„°: {len(documents_to_add)}ê°œ")

    # 6) ì›ê²© ChromaDBì— ë°ì´í„° ì¶”ê°€
    if documents_to_add:
        vectordb.add_documents(documents_to_add)
        print(f"âœ… ì›ê²© ChromaDBì— {len(documents_to_add)}ê°œ ë¬¸ì„œ ì €ì¥ ì™„ë£Œ!")
    else:
        print("ì¶”ê°€í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")

def test_remote_connection():
    """ì›ê²© ChromaDB ì—°ê²° í…ŒìŠ¤íŠ¸"""
    try:
        chroma_client = get_chroma_client()
        # ì»¬ë ‰ì…˜ ìƒì„±/ì—°ê²° í…ŒìŠ¤íŠ¸
        collection = chroma_client.get_or_create_collection(name=HISTORY_COLLECTION_NAME)
        print(f"âœ… ì›ê²© ChromaDB ì—°ê²° ì„±ê³µ!")
        print(f"ì»¬ë ‰ì…˜: {HISTORY_COLLECTION_NAME}")
        print(f"ì €ì¥ëœ ë¬¸ì„œ ìˆ˜: {collection.count()}")
        return True
    except Exception as e:
        print(f"âŒ ì›ê²© ChromaDB ì—°ê²° ì‹¤íŒ¨: {e}")
        return False

def reset_collection():
    """ì»¬ë ‰ì…˜ ì‚­ì œ í›„ ì¬ìƒì„±"""
    chroma_client = get_chroma_client()
    
    # ì»¬ë ‰ì…˜ ì‚­ì œ
    try:
        chroma_client.delete_collection(name=HISTORY_COLLECTION_NAME)
        print(f"âœ… ì»¬ë ‰ì…˜ {HISTORY_COLLECTION_NAME} ì‚­ì œ ì™„ë£Œ")
    except:
        print("ì»¬ë ‰ì…˜ì´ ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ ì´ë¯¸ ì‚­ì œë¨")
    
    # ìƒˆ ì»¬ë ‰ì…˜ ìƒì„±
    chroma_client.create_collection(name=HISTORY_COLLECTION_NAME)
    print(f"âœ… ìƒˆ ì»¬ë ‰ì…˜ {HISTORY_COLLECTION_NAME} ìƒì„± ì™„ë£Œ")

if __name__ == "__main__":
    if test_remote_connection():
        # ë°©ë²• 1 ë˜ëŠ” ë°©ë²• 2 ì¤‘ ì„ íƒ
        reset_collection()  # ì»¬ë ‰ì…˜ ì‚­ì œ í›„ ì¬ìƒì„±
        # clear_collection_data()  # ë°ì´í„°ë§Œ ì‚­ì œ
        
        save_emp_docs()
        print("=== ì›ê²© ChromaDB ì €ì¥ ì™„ë£Œ ===")

