{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6613786",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import chromadb\n",
    "import os\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 환경 변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "def get_chroma_client():\n",
    "    \"\"\"원격 ChromaDB 클라이언트 생성 (데이터베이스 포함)\"\"\"\n",
    "    client = chromadb.HttpClient(\n",
    "        host=\"chromadb-1.skala25a.project.skala-ai.com\",\n",
    "        port=443,\n",
    "        ssl=True,\n",
    "        headers={\n",
    "            \"Authorization\": \"Basic YWRtaW46U2thbGEyNWEhMjMk\"\n",
    "        },\n",
    "        database=\"nav7\"  # 데이터베이스 이름 지정\n",
    "    )\n",
    "    \n",
    "    return client\n",
    "\n",
    "def find_best_match(query_text: str, user_id: str):\n",
    "    \"\"\"쿼리에 가장 적합한 인재 찾기\"\"\"\n",
    "    \n",
    "    # 1. 상위 5명 정보 가져오기\n",
    "    candidates = get_top5_info(query_text, user_id)\n",
    "    print(\"후보자들:\")\n",
    "    print(candidates)\n",
    "    \n",
    "    # 2. LLM으로 1명 선택\n",
    "    llm_choice = llm_select(query_text, candidates)\n",
    "    print(\"LLM 선택:\")\n",
    "    print(llm_choice)\n",
    "    \n",
    "    # 3. 선택된 profileId로 상세 정보 반환\n",
    "    profile_id = re.search(r'profileId\\d+', llm_choice)\n",
    "    if profile_id:\n",
    "        return get_employee_detail(profile_id.group(0))\n",
    "    else:\n",
    "        return \"선택된 인재를 찾을 수 없습니다.\"\n",
    "\n",
    "def get_top5_info(query_text, user_id):\n",
    "    \"\"\"상위 5명 간단 정보\"\"\"\n",
    "    client = get_chroma_client()\n",
    "    collection_name = os.getenv(\"JSON_HISTORY_COLLECTION_NAME\")\n",
    "    collection = client.get_collection(name=collection_name)\n",
    "\n",
    "    # model_path=\"c:/Users/Administrator/Desktop/김현준/최종프로젝트/nav-ai/model/ko-sroberta-multitask\"\n",
    "    # embedding_model = SentenceTransformer(model_path)\n",
    "    embedding_model = SentenceTransformer(os.getenv(\"EMBEDDING_MODEL_NAME\"))\n",
    "    query_embedding = embedding_model.encode([query_text]).tolist()\n",
    "    \n",
    "    results = collection.query(query_embeddings=query_embedding, n_results=20, include=['metadatas'])\n",
    "    \n",
    "    # 중복 제거로 5명 선택\n",
    "    seen = set()\n",
    "    top5 = []\n",
    "    for meta in results['metadatas'][0]:\n",
    "        profile_id = meta.get('profileId')  # profileId 가져오기\n",
    "        if profile_id and profile_id not in seen and profile_id != user_id:\n",
    "            seen.add(profile_id)\n",
    "            top5.append(profile_id)\n",
    "            if len(top5) == 5:\n",
    "                break\n",
    "    \n",
    "    # 각 profileId별 전체 경력 정보 구성\n",
    "    info = \"\"\n",
    "    for i, profile_id in enumerate(top5, 1):\n",
    "        # 해당 profileId의 모든 경력 데이터 가져오기\n",
    "        emp_data = collection.get(where={\"profileId\": profile_id}, include=['metadatas'])\n",
    "        \n",
    "        if not emp_data['metadatas']:\n",
    "            continue\n",
    "            \n",
    "        first_meta = emp_data['metadatas'][0]\n",
    "        \n",
    "        info += f\"\\n{i}. profileId: {profile_id}\\n\"\n",
    "        info += f\"   사번: {first_meta['사번']}\\n\"\n",
    "        info += f\"   Grade: {first_meta['grade']}\\n\"\n",
    "        info += f\"   입사년도: {first_meta['입사년도']}\\n\"\n",
    "        info += f\"   경력흐름:\\n\"\n",
    "        \n",
    "        # 연차순으로 정렬해서 경력흐름 구성\n",
    "        careers = sorted(emp_data['metadatas'], key=lambda x: x['연차'])\n",
    "        \n",
    "        for j, career in enumerate(careers, 1):\n",
    "            info += f\"     {j}. {career['연차']} - {career['역할']}\\n\"\n",
    "            info += f\"        스킬셋: {career['스킬셋']}\\n\"\n",
    "            info += f\"        도메인: {career['도메인']}\\n\"\n",
    "            info += f\"        프로젝트규모: {career['프로젝트규모']}\\n\"\n",
    "            info += f\"        요약: {career['요약']}\\n\"\n",
    "        \n",
    "        info += \"-\" * 50 + \"\\n\"\n",
    "    \n",
    "    return info\n",
    "\n",
    "def llm_select(query_text, candidates):\n",
    "    \"\"\"LLM으로 1명 선택\"\"\"\n",
    "    llm = ChatOpenAI(model=os.getenv(\"MODEL_NAME\"), temperature=0.3)\n",
    "    \n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"query\", \"candidates\"],\n",
    "        template=\"\"\"\n",
    "    쿼리에 가장 적합한 인재 1명을 선택해주세요.\n",
    "\n",
    "    **사용자 요청:**\n",
    "    {query}\n",
    "\n",
    "    **후보자들:**\n",
    "    {candidates}\n",
    "\n",
    "    **평가 기준:**\n",
    "    1. 쿼리와의 관련성 (기술 스택, 경험, 역할 등)\n",
    "    2. 경력 수준과 적합성\n",
    "    3. 도메인 경험\n",
    "    4. 성장 가능성 및 전환 가능성\n",
    "\n",
    "    선택: [profileId]\n",
    "    이유: [간단한 선택 이유]\n",
    "    \"\"\"\n",
    "    )\n",
    "    \n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    return chain.invoke({\"query\": query_text, \"candidates\": candidates})\n",
    "\n",
    "def get_employee_detail(profile_id):\n",
    "    \"\"\"선택된 사원 상세 정보\"\"\"\n",
    "    client = get_chroma_client()\n",
    "    collection = client.get_collection(name=os.getenv(\"JSON_HISTORY_COLLECTION_NAME\"))\n",
    "    \n",
    "    emp_data = collection.get(where={\"profileId\": profile_id}, include=['metadatas', 'documents'])\n",
    "\n",
    "    if not emp_data['metadatas']:\n",
    "        return f\"profileId '{profile_id}'를 찾을 수 없습니다.\"\n",
    "    \n",
    "    result = f\"=== 선택된 사원 ===\\n\"\n",
    "    first_meta = emp_data['metadatas'][0]\n",
    "    result += f\"profileId: {first_meta['profileId']}\\n\"\n",
    "    result += f\"사번: {first_meta['사번']}\\n\"\n",
    "    result += f\"Grade: {first_meta['grade']}\\n\"\n",
    "    result += f\"입사년도: {first_meta['입사년도']}\\n\"\n",
    "    result += f\"총 경력 수: {len(emp_data['metadatas'])}개\\n\\n\"\n",
    "    \n",
    "    result += \"경력 상세:\\n\"\n",
    "    for j, (meta, doc) in enumerate(zip(emp_data['metadatas'], emp_data['documents']), 1):\n",
    "        result += f\"  경력 {j}: {meta['연차']} - {meta['역할']}\\n\"\n",
    "        result += f\"    스킬셋: {meta['스킬셋']}\\n\"\n",
    "        result += f\"    도메인: {meta['도메인']}\\n\"\n",
    "        result += f\"    프로젝트규모: {meta['프로젝트규모']}\\n\"\n",
    "        result += f\"    요약: {meta['요약']}\\n\"\n",
    "        result += f\"    상세내용: {doc}\\n\\n\"\n",
    "    \n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82315235",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"jhgan/ko-sroberta-multitask\")\n",
    "model = AutoModel.from_pretrained(\"jhgan/ko-sroberta-multitask\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c42673e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
